2020-03-02 12:54:49,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /home/paradox/hadoop/etc/hadoop:/home/paradox/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/paradox/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/paradox/hadoop/share/hadoop/common/lib/httpcore-4.4.10.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-core-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/httpclient-4.5.6.jar:/home/paradox/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/home/paradox/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/paradox/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/paradox/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/paradox/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/home/paradox/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/paradox/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-nfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-kms-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs:/home/paradox/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/paradox/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn:/home/paradox/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 1.8.0_242
************************************************************/
2020-03-02 12:54:49,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-02 12:54:49,915 ERROR org.apache.hadoop.conf.Configuration: error parsing conf hdfs-site.xml
com.ctc.wstx.exc.WstxParsingException: Unexpected '<' character in element (missing closing '>'?)
 at [row,col,system-id]: [21,1,"file:/home/paradox/hadoop/etc/hadoop/hdfs-site.xml"]
	at com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:621)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:491)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:475)
	at com.ctc.wstx.sr.BasicStreamReader.handleNsAttrs(BasicStreamReader.java:3088)
	at com.ctc.wstx.sr.BasicStreamReader.handleStartElem(BasicStreamReader.java:3043)
	at com.ctc.wstx.sr.BasicStreamReader.nextFromTree(BasicStreamReader.java:2919)
	at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1123)
	at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3320)
	at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3114)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3007)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2968)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2848)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1200)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1812)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1789)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)
	at org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)
	at org.apache.hadoop.util.StringUtils.startupShutdownMessage(StringUtils.java:723)
	at org.apache.hadoop.util.StringUtils.startupShutdownMessage(StringUtils.java:707)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2899)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2924)
2020-03-02 12:54:49,917 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.lang.RuntimeException: com.ctc.wstx.exc.WstxParsingException: Unexpected '<' character in element (missing closing '>'?)
 at [row,col,system-id]: [21,1,"file:/home/paradox/hadoop/etc/hadoop/hdfs-site.xml"]
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3024)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2968)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2848)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1200)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1812)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1789)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)
	at org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)
	at org.apache.hadoop.util.StringUtils.startupShutdownMessage(StringUtils.java:723)
	at org.apache.hadoop.util.StringUtils.startupShutdownMessage(StringUtils.java:707)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2899)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2924)
Caused by: com.ctc.wstx.exc.WstxParsingException: Unexpected '<' character in element (missing closing '>'?)
 at [row,col,system-id]: [21,1,"file:/home/paradox/hadoop/etc/hadoop/hdfs-site.xml"]
	at com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:621)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:491)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:475)
	at com.ctc.wstx.sr.BasicStreamReader.handleNsAttrs(BasicStreamReader.java:3088)
	at com.ctc.wstx.sr.BasicStreamReader.handleStartElem(BasicStreamReader.java:3043)
	at com.ctc.wstx.sr.BasicStreamReader.nextFromTree(BasicStreamReader.java:2919)
	at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1123)
	at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3320)
	at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3114)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3007)
	... 12 more
2020-03-02 12:54:49,921 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.lang.RuntimeException: com.ctc.wstx.exc.WstxParsingException: Unexpected '<' character in element (missing closing '>'?)
 at [row,col,system-id]: [21,1,"file:/home/paradox/hadoop/etc/hadoop/hdfs-site.xml"]
2020-03-02 12:54:49,990 ERROR org.apache.hadoop.conf.Configuration: error parsing conf hdfs-site.xml
com.ctc.wstx.exc.WstxParsingException: Unexpected '<' character in element (missing closing '>'?)
 at [row,col,system-id]: [21,1,"file:/home/paradox/hadoop/etc/hadoop/hdfs-site.xml"]
	at com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:621)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:491)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:475)
	at com.ctc.wstx.sr.BasicStreamReader.handleNsAttrs(BasicStreamReader.java:3088)
	at com.ctc.wstx.sr.BasicStreamReader.handleStartElem(BasicStreamReader.java:3043)
	at com.ctc.wstx.sr.BasicStreamReader.nextFromTree(BasicStreamReader.java:2919)
	at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1123)
	at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3320)
	at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3114)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3007)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2968)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2848)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1200)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1812)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1789)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
2020-03-02 12:56:05,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /home/paradox/hadoop/etc/hadoop:/home/paradox/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/paradox/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/paradox/hadoop/share/hadoop/common/lib/httpcore-4.4.10.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-core-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/httpclient-4.5.6.jar:/home/paradox/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/home/paradox/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/paradox/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/paradox/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/paradox/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/home/paradox/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/paradox/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-nfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-kms-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs:/home/paradox/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/paradox/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn:/home/paradox/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 1.8.0_242
************************************************************/
2020-03-02 12:56:05,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-02 12:56:06,220 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/paradox/hdata/dfs/data
2020-03-02 12:56:06,295 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-03-02 12:56:06,347 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-03-02 12:56:06,347 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-02 12:56:06,473 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-03-02 12:56:06,475 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-02 12:56:06,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2020-03-02 12:56:06,479 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-03-02 12:56:06,481 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-02 12:56:06,497 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-03-02 12:56:06,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-03-02 12:56:06,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-03-02 12:56:06,525 INFO org.eclipse.jetty.util.log: Logging initialized @980ms
2020-03-02 12:56:06,594 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-02 12:56:06,596 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-02 12:56:06,603 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-02 12:56:06,604 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-02 12:56:06,604 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-02 12:56:06,604 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-02 12:56:06,619 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35839
2020-03-02 12:56:06,620 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-03-02 12:56:06,641 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5167f57d{/logs,file:///home/paradox/hadoop/logs/,AVAILABLE}
2020-03-02 12:56:06,642 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18f8cd79{/static,file:///home/paradox/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-03-02 12:56:06,685 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@4b34fff9{/,file:///home/paradox/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-03-02 12:56:06,689 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@2a3888c1{HTTP/1.1,[http/1.1]}{localhost:35839}
2020-03-02 12:56:06,689 INFO org.eclipse.jetty.server.Server: Started @1143ms
2020-03-02 12:56:06,872 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-03-02 12:56:06,876 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-03-02 12:56:06,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = paradox
2020-03-02 12:56:06,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-02 12:56:06,906 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-03-02 12:56:06,916 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-03-02 12:56:07,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-03-02 12:56:07,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-03-02 12:56:07,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-03-02 12:56:07,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-03-02 12:56:07,370 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-02 12:56:07,373 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-03-02 12:56:08,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:09,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:10,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:11,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:12,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:13,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:14,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:15,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:16,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:17,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:17,997 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-03-02 12:56:24,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:25,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:26,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:27,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:28,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:29,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:30,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:31,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:32,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:33,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:33,014 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-03-02 12:56:39,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:40,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:41,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:42,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:43,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:44,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:45,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:46,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:47,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:48,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:48,032 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-03-02 12:56:54,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:55,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:56,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:57,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:58,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:56:59,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:00,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:01,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:02,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:03,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:03,055 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-03-02 12:57:09,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:10,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:11,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:12,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:13,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:14,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:15,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:16,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:17,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:18,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-03-02 12:57:18,078 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2020-03-02 12:57:18,760 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-03-02 12:57:18,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2020-03-02 12:58:10,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.1
STARTUP_MSG:   classpath = /home/paradox/hadoop/etc/hadoop:/home/paradox/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/home/paradox/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/home/paradox/hadoop/share/hadoop/common/lib/httpcore-4.4.10.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/home/paradox/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-core-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-compress-1.18.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/httpclient-4.5.6.jar:/home/paradox/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/home/paradox/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/home/paradox/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/home/paradox/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/paradox/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/home/paradox/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/paradox/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/home/paradox/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/home/paradox/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/home/paradox/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/home/paradox/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/home/paradox/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/paradox/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/paradox/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-nfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/common/hadoop-kms-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs:/home/paradox/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/home/paradox/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/paradox/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/home/paradox/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn:/home/paradox/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/paradox/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/home/paradox/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar
STARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z
STARTUP_MSG:   java = 1.8.0_242
************************************************************/
2020-03-02 12:58:10,687 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2020-03-02 12:58:10,936 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/home/paradox/hdata/dfs/data
2020-03-02 12:58:11,013 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2020-03-02 12:58:11,064 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2020-03-02 12:58:11,064 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2020-03-02 12:58:11,193 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-03-02 12:58:11,194 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2020-03-02 12:58:11,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2020-03-02 12:58:11,198 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-03-02 12:58:11,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2020-03-02 12:58:11,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2020-03-02 12:58:11,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2020-03-02 12:58:11,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2020-03-02 12:58:11,243 INFO org.eclipse.jetty.util.log: Logging initialized @914ms
2020-03-02 12:58:11,310 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-03-02 12:58:11,313 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2020-03-02 12:58:11,317 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-03-02 12:58:11,319 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-03-02 12:58:11,319 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-03-02 12:58:11,319 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-03-02 12:58:11,334 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35565
2020-03-02 12:58:11,335 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-03-02 12:58:11,357 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5167f57d{/logs,file:///home/paradox/hadoop/logs/,AVAILABLE}
2020-03-02 12:58:11,357 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@18f8cd79{/static,file:///home/paradox/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2020-03-02 12:58:11,400 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@4b34fff9{/,file:///home/paradox/hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2020-03-02 12:58:11,404 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@2a3888c1{HTTP/1.1,[http/1.1]}{localhost:35565}
2020-03-02 12:58:11,404 INFO org.eclipse.jetty.server.Server: Started @1075ms
2020-03-02 12:58:11,550 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2020-03-02 12:58:11,554 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2020-03-02 12:58:11,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = paradox
2020-03-02 12:58:11,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2020-03-02 12:58:11,585 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-03-02 12:58:11,594 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2020-03-02 12:58:11,710 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2020-03-02 12:58:11,722 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2020-03-02 12:58:11,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2020-03-02 12:58:11,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2020-03-02 12:58:11,740 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2020-03-02 12:58:11,741 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2020-03-02 12:58:11,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2020-03-02 12:58:11,955 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-03-02 12:58:11,959 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /home/paradox/hdata/dfs/data/in_use.lock acquired by nodename 11581@ubuntu
2020-03-02 12:58:11,960 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/home/paradox/hdata/dfs/data is not formatted for namespace 164801920. Formatting...
2020-03-02 12:58:11,960 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-c161b1e3-7b26-4940-a89c-b248f84498f6 for directory /home/paradox/hdata/dfs/data 
2020-03-02 12:58:11,977 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-497405921-127.0.1.1-1583125060437
2020-03-02 12:58:11,977 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /home/paradox/hdata/dfs/data/current/BP-497405921-127.0.1.1-1583125060437
2020-03-02 12:58:11,977 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/home/paradox/hdata/dfs/data and block pool id BP-497405921-127.0.1.1-1583125060437 is not formatted. Formatting ...
2020-03-02 12:58:11,978 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-497405921-127.0.1.1-1583125060437 directory /home/paradox/hdata/dfs/data/current/BP-497405921-127.0.1.1-1583125060437/current
2020-03-02 12:58:11,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=164801920;bpid=BP-497405921-127.0.1.1-1583125060437;lv=-57;nsInfo=lv=-65;cid=CID-b583fb67-6af4-4503-8142-2137411db3c8;nsid=164801920;c=1583125060437;bpid=BP-497405921-127.0.1.1-1583125060437;dnuuid=null
2020-03-02 12:58:11,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 26fcf124-e200-4b76-afab-48522e81d82c
2020-03-02 12:58:12,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c161b1e3-7b26-4940-a89c-b248f84498f6
2020-03-02 12:58:12,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/home/paradox/hdata/dfs/data, StorageType: DISK
2020-03-02 12:58:12,048 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2020-03-02 12:58:12,053 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /home/paradox/hdata/dfs/data
2020-03-02 12:58:12,058 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /home/paradox/hdata/dfs/data
2020-03-02 12:58:12,060 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-497405921-127.0.1.1-1583125060437
2020-03-02 12:58:12,061 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-497405921-127.0.1.1-1583125060437 on volume /home/paradox/hdata/dfs/data...
2020-03-02 12:58:12,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-497405921-127.0.1.1-1583125060437 on /home/paradox/hdata/dfs/data: 25ms
2020-03-02 12:58:12,086 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-497405921-127.0.1.1-1583125060437: 26ms
2020-03-02 12:58:12,087 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-497405921-127.0.1.1-1583125060437 on volume /home/paradox/hdata/dfs/data...
2020-03-02 12:58:12,087 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /home/paradox/hdata/dfs/data/current/BP-497405921-127.0.1.1-1583125060437/current/replicas doesn't exist 
2020-03-02 12:58:12,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-497405921-127.0.1.1-1583125060437 on volume /home/paradox/hdata/dfs/data: 3ms
2020-03-02 12:58:12,091 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-497405921-127.0.1.1-1583125060437: 5ms
2020-03-02 12:58:12,093 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-497405921-127.0.1.1-1583125060437 on volume /home/paradox/hdata/dfs/data
2020-03-02 12:58:12,095 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/paradox/hdata/dfs/data, DS-c161b1e3-7b26-4940-a89c-b248f84498f6): finished scanning block pool BP-497405921-127.0.1.1-1583125060437
2020-03-02 12:58:12,135 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/home/paradox/hdata/dfs/data, DS-c161b1e3-7b26-4940-a89c-b248f84498f6): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-03-02 12:58:12,136 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 3/2/20 2:13 PM with interval of 21600000ms
2020-03-02 12:58:12,141 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-497405921-127.0.1.1-1583125060437 (Datanode Uuid 26fcf124-e200-4b76-afab-48522e81d82c) service to localhost/127.0.0.1:9000 beginning handshake with NN
2020-03-02 12:58:12,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-497405921-127.0.1.1-1583125060437 (Datanode Uuid 26fcf124-e200-4b76-afab-48522e81d82c) service to localhost/127.0.0.1:9000 successfully registered with NN
2020-03-02 12:58:12,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-03-02 12:58:12,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xaa89379995f5bbcd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-03-02 12:58:12,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-497405921-127.0.1.1-1583125060437
2020-03-02 13:00:51,962 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "ubuntu/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy16.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-03-02 13:00:52,607 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2020-03-02 13:00:52,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
